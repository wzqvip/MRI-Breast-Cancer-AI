{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BAD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset, DataLoader\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Step 1: Load DICOM files\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\WANGZ\\miniconda3\\envs\\cs320\\lib\\site-packages\\torchvision\\__init__.py:10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Don't re-order these, we need to load the _C extension (done when importing\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# .extensions) before entering _meta_registrations.\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextension\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _HAS_OPS  \u001b[38;5;66;03m# usort:skip\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _meta_registrations, datasets, io, models, ops, transforms, utils  \u001b[38;5;66;03m# usort:skip\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\WANGZ\\miniconda3\\envs\\cs320\\lib\\site-packages\\torchvision\\models\\__init__.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malexnet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvnext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdensenet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mefficientnet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\WANGZ\\miniconda3\\envs\\cs320\\lib\\site-packages\\torchvision\\models\\convnext.py:8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn, Tensor\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m functional \u001b[38;5;28;01mas\u001b[39;00m F\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Conv2dNormActivation, Permute\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstochastic_depth\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StochasticDepth\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_presets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageClassification\n",
      "File \u001b[1;32mc:\\Users\\WANGZ\\miniconda3\\envs\\cs320\\lib\\site-packages\\torchvision\\ops\\__init__.py:23\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgiou_loss\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generalized_box_iou_loss\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Conv2dNormActivation, Conv3dNormActivation, FrozenBatchNorm2d, MLP, Permute, SqueezeExcitation\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpoolers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MultiScaleRoIAlign\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mps_roi_align\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ps_roi_align, PSRoIAlign\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mps_roi_pool\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ps_roi_pool, PSRoIPool\n",
      "File \u001b[1;32mc:\\Users\\WANGZ\\miniconda3\\envs\\cs320\\lib\\site-packages\\torchvision\\ops\\poolers.py:10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mboxes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m box_area\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _log_api_usage_once\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mroi_align\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m roi_align\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# copying result_idx_in_level to a specific index in result[]\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# is not supported by ONNX tracing yet.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# _onnx_merge_levels() is an implementation supported by ONNX\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# that merges the levels to the right indices\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39munused\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_onnx_merge_levels\u001b[39m(levels: Tensor, unmerged_results: List[Tensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n",
      "File \u001b[1;32mc:\\Users\\WANGZ\\miniconda3\\envs\\cs320\\lib\\site-packages\\torchvision\\ops\\roi_align.py:7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn, Tensor\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_compile_supported\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjit\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mannotations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BroadcastingList2\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodules\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _pair\n",
      "File \u001b[1;32mc:\\Users\\WANGZ\\miniconda3\\envs\\cs320\\lib\\site-packages\\torch\\_dynamo\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m convert_frame, eval_frame, resume_execution\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m list_backends, lookup_backend, register_backend\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallback\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m callback_handler, on_compile_end, on_compile_start\n",
      "File \u001b[1;32mc:\\Users\\WANGZ\\miniconda3\\envs\\cs320\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py:53\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_python_dispatch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     48\u001b[0m     _disable_current_modes,\n\u001b[0;32m     49\u001b[0m     is_in_torch_dispatch_mode,\n\u001b[0;32m     50\u001b[0m )\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_traceback\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CapturedTraceback, format_traceback_short\n\u001b[1;32m---> 53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config, exc, trace_rules\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbytecode_analysis\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m remove_dead_code, remove_pointless_jumps\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbytecode_transformation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     56\u001b[0m     check_inst_exn_tab_entries_valid,\n\u001b[0;32m     57\u001b[0m     Instruction,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     60\u001b[0m     transform_code_object,\n\u001b[0;32m     61\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\WANGZ\\miniconda3\\envs\\cs320\\lib\\site-packages\\torch\\_dynamo\\trace_rules.py:46\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresume_execution\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TORCH_DYNAMO_RESUME_IN_PREFIX\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m getfile, hashable, NP_SUPPORTED_MODULES, unwrap_if_wrapper\n\u001b[1;32m---> 46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvariables\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     47\u001b[0m     BuiltinVariable,\n\u001b[0;32m     48\u001b[0m     FunctionalCallVariable,\n\u001b[0;32m     49\u001b[0m     FunctorchHigherOrderVariable,\n\u001b[0;32m     50\u001b[0m     NestedUserFunctionVariable,\n\u001b[0;32m     51\u001b[0m     PolyfilledFunctionVariable,\n\u001b[0;32m     52\u001b[0m     SkipFunctionVariable,\n\u001b[0;32m     53\u001b[0m     TorchInGraphFunctionVariable,\n\u001b[0;32m     54\u001b[0m     UserFunctionVariable,\n\u001b[0;32m     55\u001b[0m     UserMethodVariable,\n\u001b[0;32m     56\u001b[0m )\n\u001b[0;32m     59\u001b[0m np: Optional[types\u001b[38;5;241m.\u001b[39mModuleType] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\WANGZ\\miniconda3\\envs\\cs320\\lib\\site-packages\\torch\\_dynamo\\variables\\__init__.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VariableTracker\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuiltin\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BuiltinVariable\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstant\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConstantVariable, EnumVariable\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mctx_manager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      5\u001b[0m     CatchWarningsCtxManagerVariable,\n\u001b[0;32m      6\u001b[0m     ContextWrappingVariable,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m     WithExitFunctionVariable,\n\u001b[0;32m     22\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\WANGZ\\miniconda3\\envs\\cs320\\lib\\site-packages\\torch\\_dynamo\\variables\\builtin.py:47\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MutableLocal, VariableTracker\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstant\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConstantVariable\n\u001b[1;32m---> 47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mctx_manager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EventVariable, StreamVariable\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdicts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     49\u001b[0m     ConstDictVariable,\n\u001b[0;32m     50\u001b[0m     DefaultDictVariable,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     54\u001b[0m     SetVariable,\n\u001b[0;32m     55\u001b[0m )\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlists\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     57\u001b[0m     BaseListVariable,\n\u001b[0;32m     58\u001b[0m     ListIteratorVariable,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     62\u001b[0m     TupleVariable,\n\u001b[0;32m     63\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\WANGZ\\miniconda3\\envs\\cs320\\lib\\site-packages\\torch\\_dynamo\\variables\\ctx_manager.py:22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msource\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AttrSource, GlobalStateSource\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VariableTracker\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     23\u001b[0m     NestedUserFunctionVariable,\n\u001b[0;32m     24\u001b[0m     UserFunctionVariable,\n\u001b[0;32m     25\u001b[0m     UserMethodVariable,\n\u001b[0;32m     26\u001b[0m     WrappedUserFunctionVariable,\n\u001b[0;32m     27\u001b[0m     WrappedUserMethodVariable,\n\u001b[0;32m     28\u001b[0m )\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01muser_defined\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UserDefinedObjectVariable\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n",
      "File \u001b[1;32mc:\\Users\\WANGZ\\miniconda3\\envs\\cs320\\lib\\site-packages\\torch\\_dynamo\\variables\\functions.py:31\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstant\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConstantVariable\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 31\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_composable\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfsdp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _fsdp_param_group\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m:\n\u001b[0;32m     33\u001b[0m     _fsdp_param_group \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\WANGZ\\miniconda3\\envs\\cs320\\lib\\site-packages\\torch\\distributed\\_composable\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcheckpoint_activation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m checkpoint\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontract\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _get_registry, contract\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfully_shard\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fully_shard\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreplicate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m replicate\n",
      "File \u001b[1;32mc:\\Users\\WANGZ\\miniconda3\\envs\\cs320\\lib\\site-packages\\torch\\distributed\\_composable\\fully_shard.py:10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_composable\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontract\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m contract\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_composable_state\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _get_module_state, _insert_module_state\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfsdp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_common_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _FSDPState\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfsdp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _annotate_modules_for_dynamo\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfsdp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_init_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     13\u001b[0m     _init_buffer_state,\n\u001b[0;32m     14\u001b[0m     _init_core_state,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     22\u001b[0m     HYBRID_SHARDING_STRATEGIES,\n\u001b[0;32m     23\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\WANGZ\\miniconda3\\envs\\cs320\\lib\\site-packages\\torch\\distributed\\fsdp\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_flat_param\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FlatParameter \u001b[38;5;28;01mas\u001b[39;00m FlatParameter\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfully_sharded_data_parallel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      3\u001b[0m     BackwardPrefetch,\n\u001b[0;32m      4\u001b[0m     CPUOffload,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m     StateDictType,\n\u001b[0;32m     19\u001b[0m )\n\u001b[0;32m     22\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBackwardPrefetch\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCPUOffload\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStateDictType\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     39\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\WANGZ\\miniconda3\\envs\\cs320\\lib\\site-packages\\torch\\distributed\\fsdp\\_flat_param.py:47\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparameter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _ParameterMeta  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtesting\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_internal\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfake_pg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FakeProcessGroup\n\u001b[1;32m---> 47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_fsdp_extensions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     48\u001b[0m     _ext_post_unflatten_transform,\n\u001b[0;32m     49\u001b[0m     _ext_pre_flatten_transform,\n\u001b[0;32m     50\u001b[0m     FSDPExtensions,\n\u001b[0;32m     51\u001b[0m )\n\u001b[0;32m     54\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFlatParameter\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFlatParamHandle\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHandleShardingStrategy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     61\u001b[0m ]\n\u001b[0;32m     63\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\WANGZ\\miniconda3\\envs\\cs320\\lib\\site-packages\\torch\\distributed\\fsdp\\_fsdp_extensions.py:6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mdist\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_shard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msharded_tensor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ShardedTensor\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_shard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msharded_tensor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mshard\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Shard\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfsdp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_shard_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      9\u001b[0m     _all_gather_dtensor,\n\u001b[0;32m     10\u001b[0m     _create_chunk_dtensor,\n\u001b[0;32m     11\u001b[0m     _create_chunk_sharded_tensor,\n\u001b[0;32m     12\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\WANGZ\\miniconda3\\envs\\cs320\\lib\\site-packages\\torch\\distributed\\_shard\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _shard_tensor, load_with_process_group, shard_module, shard_parameter\n",
      "File \u001b[1;32mc:\\Users\\WANGZ\\miniconda3\\envs\\cs320\\lib\\site-packages\\torch\\distributed\\_shard\\api.py:9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distributed_c10d\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_shard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msharded_tensor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ShardedTensor\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msharder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sharder\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msharding_plan\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ShardingPlan\n",
      "File \u001b[1;32mc:\\Users\\WANGZ\\miniconda3\\envs\\cs320\\lib\\site-packages\\torch\\distributed\\_shard\\sharded_tensor\\__init__.py:8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_shard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mop_registry_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _decorator_func\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      9\u001b[0m     _CUSTOM_SHARDED_OPS,\n\u001b[0;32m     10\u001b[0m     _SHARDED_OPS,\n\u001b[0;32m     11\u001b[0m     Shard,\n\u001b[0;32m     12\u001b[0m     ShardedTensor,\n\u001b[0;32m     13\u001b[0m     ShardedTensorBase,\n\u001b[0;32m     14\u001b[0m     ShardedTensorMetadata,\n\u001b[0;32m     15\u001b[0m     TensorProperties,\n\u001b[0;32m     16\u001b[0m )\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetadata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ShardMetadata  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n",
      "File \u001b[1;32mc:\\Users\\WANGZ\\miniconda3\\envs\\cs320\\lib\\site-packages\\torch\\distributed\\_shard\\sharded_tensor\\api.py:31\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _pytree \u001b[38;5;28;01mas\u001b[39;00m pytree\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetadata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ShardedTensorMetadata, TensorProperties\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshard\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m reshard_local_shard, reshuffle_local_shard\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mshard\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Shard\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     34\u001b[0m     _flatten_tensor_size,\n\u001b[0;32m     35\u001b[0m     _parse_and_validate_remote_device,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     38\u001b[0m     build_metadata_from_local_shards,\n\u001b[0;32m     39\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\WANGZ\\miniconda3\\envs\\cs320\\lib\\site-packages\\torch\\distributed\\_shard\\sharded_tensor\\reshard.py:14\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_shard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetadata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ShardMetadata\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_shard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msharding_spec\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_internals\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     11\u001b[0m     get_chunked_dim_size,\n\u001b[0;32m     12\u001b[0m     get_split_size,\n\u001b[0;32m     13\u001b[0m )\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m all_to_all, all_to_all_single\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mshard\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Shard\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_idx_from_placements\u001b[39m(placements, current_rank) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\WANGZ\\miniconda3\\envs\\cs320\\lib\\site-packages\\torch\\distributed\\nn\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mdistributed\u001b[38;5;241m.\u001b[39mrpc\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mremote_module\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RemoteModule\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:688\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:879\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:975\u001b[0m, in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1074\u001b[0m, in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Step 1: Load DICOM files\n",
    "\n",
    "def load_dicom_series(folder_path):\n",
    "    \"\"\"\n",
    "    Load a DICOM series from a folder path and return it as a 3D numpy array.\n",
    "    \"\"\"\n",
    "    reader = sitk.ImageSeriesReader()\n",
    "    dicom_files = reader.GetGDCMSeriesFileNames(folder_path)\n",
    "    if len(dicom_files) == 0:\n",
    "        raise ValueError(f\"No DICOM files found in the directory: {folder_path}\")\n",
    "    reader.SetFileNames(dicom_files)\n",
    "    image = reader.Execute()  # SimpleITK image\n",
    "    array = sitk.GetArrayFromImage(image)  # Convert to numpy array\n",
    "    return array\n",
    "\n",
    "# Step 2: Dataset definition\n",
    "\n",
    "class MultiModalDataset(Dataset):\n",
    "    def __init__(self, data_dir, labels_csv, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_dir (str): Path to the root directory containing patient folders.\n",
    "            labels_csv (str): Path to the CSV file containing patient IDs and labels.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.data_dir = data_dir\n",
    "        self.labels = pd.read_csv(labels_csv)\n",
    "        self.transform = transform\n",
    "        self.samples = self._generate_samples()\n",
    "\n",
    "    def _generate_samples(self):\n",
    "        \"\"\"\n",
    "        Generate a list of samples considering multiple scans per patient.\n",
    "        Each sample corresponds to a specific scan session.\n",
    "        \"\"\"\n",
    "        samples = []\n",
    "        for _, row in self.labels.iterrows():\n",
    "            patient_id = row[\"PatientID\"]\n",
    "            label = row[\"Label\"]\n",
    "            patient_folder = os.path.join(self.data_dir, patient_id)\n",
    "            if os.path.exists(patient_folder):\n",
    "                for scan_session in os.listdir(patient_folder):\n",
    "                    session_path = os.path.join(patient_folder, scan_session)\n",
    "                    if os.path.isdir(session_path):\n",
    "                        samples.append({\"session_path\": session_path, \"label\": label})\n",
    "        return samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        session_path = sample[\"session_path\"]\n",
    "        label = sample[\"label\"]\n",
    "\n",
    "        # Load multimodal data\n",
    "        try:\n",
    "            ct_path = os.path.join(session_path, 'CT/CTAC')\n",
    "            pet_path = os.path.join(session_path, 'PT/PET')\n",
    "            mr_path = os.path.join(session_path, 'MR')\n",
    "\n",
    "            ct_data = load_dicom_series(ct_path) if os.path.exists(ct_path) else np.zeros((64, 64, 64))\n",
    "            pet_data = load_dicom_series(pet_path) if os.path.exists(pet_path) else np.zeros((64, 64, 64))\n",
    "            mr_data = None\n",
    "            if os.path.exists(mr_path):\n",
    "                mr_data = [load_dicom_series(os.path.join(mr_path, subfolder))\n",
    "                           for subfolder in os.listdir(mr_path)\n",
    "                           if os.path.isdir(os.path.join(mr_path, subfolder))]\n",
    "\n",
    "            # Preprocess data (e.g., resize, normalize)\n",
    "            ct_data = self.preprocess(ct_data)\n",
    "            pet_data = self.preprocess(pet_data)\n",
    "            mr_data = [self.preprocess(mr) for mr in mr_data] if mr_data else [np.zeros((64, 64, 64))]\n",
    "\n",
    "            # Combine modalities (e.g., stack along a new dimension)\n",
    "            combined_data = np.stack([ct_data, pet_data] + mr_data[:1], axis=0)  # Shape: (modalities, depth, height, width)\n",
    "\n",
    "            if self.transform:\n",
    "                combined_data = self.transform(torch.tensor(combined_data, dtype=torch.float32))\n",
    "\n",
    "            return combined_data, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        except ValueError as e:\n",
    "            print(f\"Error loading data for session: {session_path} - {e}\")\n",
    "            return None, None\n",
    "\n",
    "    @staticmethod\n",
    "    def preprocess(image):\n",
    "        \"\"\"\n",
    "        Preprocess the image: normalize and resize to (64, 64, 64).\n",
    "        \"\"\"\n",
    "        if image is None or np.all(image == 0):\n",
    "            return np.zeros((64, 64, 64))\n",
    "        image = (image - np.min(image)) / (np.max(image) - np.min(image) + 1e-8)  # Normalize\n",
    "        from skimage.transform import resize\n",
    "        return resize(image, (64, 64, 64), mode='constant', anti_aliasing=True)\n",
    "\n",
    "# Step 3: Define the multimodal model\n",
    "\n",
    "class MultiModalNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiModalNet, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(3, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv3d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool3d(2, 2)\n",
    "        self.fc1 = nn.Linear(32 * 16 * 16 * 16, 128)  # Updated to match flattened size\n",
    "        self.fc2 = nn.Linear(128, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)  # Flatten dynamically based on batch size\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Step 4: Training loop\n",
    "\n",
    "def train_model(model, dataloader, criterion, optimizer, num_epochs=20, save_path=\"best_model.pth\"):\n",
    "    best_loss = float('inf')\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        for inputs, labels in dataloader:\n",
    "            if inputs is None or labels is None:\n",
    "                continue\n",
    "\n",
    "            inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        avg_loss = epoch_loss / len(dataloader)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss}\")\n",
    "\n",
    "        # Save the model if it has the best loss so far\n",
    "        if avg_loss < best_loss:\n",
    "            best_loss = avg_loss\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"Model saved with loss {best_loss}\")\n",
    "\n",
    "# Step 5: Main script\n",
    "\n",
    "data_dir = \"../datasets/PyDownloader/QIN-BREAST/\"\n",
    "labels_csv = \"./QIN_labels.csv\"\n",
    "transform = transforms.Compose([\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "dataset = MultiModalDataset(data_dir, labels_csv, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "model = MultiModalNet().to('cuda')\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train_model(model, dataloader, criterion, optimizer, num_epochs=20, save_path=\"best_model.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5ch data training\n",
    "\n",
    "fill 0 when channel doesn't exist\n",
    "\n",
    "CT\n",
    "PET\n",
    "MR_DWI\n",
    "MR_T1\n",
    "MR_dynamic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import SimpleITK as sitk\n",
    "from skimage.transform import resize\n",
    "\n",
    "def load_dicom_series(folder_path):\n",
    "    \"\"\"\n",
    "    读取DICOM序列并返回 (D, H, W) 的 numpy array, 若失败则返回None\n",
    "    \"\"\"\n",
    "    if not folder_path or not os.path.isdir(folder_path):\n",
    "        return None\n",
    "\n",
    "    reader = sitk.ImageSeriesReader()\n",
    "    dicom_files = reader.GetGDCMSeriesFileNames(folder_path)\n",
    "    if len(dicom_files) == 0:\n",
    "        return None\n",
    "\n",
    "    reader.SetFileNames(dicom_files)\n",
    "    image = reader.Execute()  # SimpleITK image\n",
    "    array = sitk.GetArrayFromImage(image)  # (D, H, W)\n",
    "    return array\n",
    "\n",
    "def normalize_and_resize(image_np, output_shape=(64, 64, 64)):\n",
    "    \"\"\"\n",
    "    将 (D, H, W) 归一化到[0,1], 并 resize 到 output_shape.\n",
    "    若 image_np=None 或全0, 返回全0占位.\n",
    "    \"\"\"\n",
    "    if image_np is None or np.all(image_np == 0):\n",
    "        return np.zeros(output_shape, dtype=np.float32)\n",
    "\n",
    "    min_val, max_val = np.min(image_np), np.max(image_np)\n",
    "    if max_val - min_val < 1e-8:\n",
    "        image_np = np.zeros_like(image_np, dtype=np.float32)\n",
    "    else:\n",
    "        image_np = (image_np - min_val) / (max_val - min_val + 1e-8)\n",
    "\n",
    "    image_resized = resize(image_np, output_shape, mode='constant', anti_aliasing=True)\n",
    "    return image_resized.astype(np.float32)\n",
    "\n",
    "class MultiModal3DDataset(Dataset):\n",
    "    \"\"\"\n",
    "    5 通道: [CT, PET, MR_DWI, MR_T1, MR_DYNAMIC]\n",
    "    \"\"\"\n",
    "    def __init__(self, csv_path, transform=None, output_shape=(64,64,64)):\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.transform = transform\n",
    "        self.output_shape = output_shape\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        label = row[\"label\"]\n",
    "\n",
    "        # 1) CT\n",
    "        ct_path = row[\"ct_path\"] if isinstance(row[\"ct_path\"], str) and row[\"ct_path\"] else None\n",
    "        ct_data = load_dicom_series(ct_path)\n",
    "        ct_data = normalize_and_resize(ct_data, self.output_shape)\n",
    "\n",
    "        # 2) PET\n",
    "        pet_path = row[\"pet_path\"] if isinstance(row[\"pet_path\"], str) and row[\"pet_path\"] else None\n",
    "        pet_data = load_dicom_series(pet_path)\n",
    "        pet_data = normalize_and_resize(pet_data, self.output_shape)\n",
    "\n",
    "        # 3) MR_DWI\n",
    "        mr_dwi_str = row[\"mr_dwi\"] if isinstance(row[\"mr_dwi\"], str) else \"\"\n",
    "        mr_dwi_data = np.zeros(self.output_shape, dtype=np.float32)\n",
    "        if mr_dwi_str:\n",
    "            dwi_list = mr_dwi_str.split(\";\")\n",
    "            if len(dwi_list) > 0:  # 这里只示范取第一个文件夹\n",
    "                dwi_arr = load_dicom_series(dwi_list[0])\n",
    "                mr_dwi_data = normalize_and_resize(dwi_arr, self.output_shape)\n",
    "\n",
    "        # 4) MR_T1\n",
    "        mr_t1_str = row[\"mr_t1\"] if isinstance(row[\"mr_t1\"], str) else \"\"\n",
    "        mr_t1_data = np.zeros(self.output_shape, dtype=np.float32)\n",
    "        if mr_t1_str:\n",
    "            t1_list = mr_t1_str.split(\";\")\n",
    "            if len(t1_list) > 0:\n",
    "                t1_arr = load_dicom_series(t1_list[0])\n",
    "                mr_t1_data = normalize_and_resize(t1_arr, self.output_shape)\n",
    "\n",
    "        # 5) MR_dynamic\n",
    "        mr_dynamic_str = row[\"mr_dynamic\"] if isinstance(row[\"mr_dynamic\"], str) else \"\"\n",
    "        mr_dynamic_data = np.zeros(self.output_shape, dtype=np.float32)\n",
    "        if mr_dynamic_str:\n",
    "            dyn_list = mr_dynamic_str.split(\";\")\n",
    "            if len(dyn_list) > 0:\n",
    "                dyn_arr = load_dicom_series(dyn_list[0])\n",
    "                mr_dynamic_data = normalize_and_resize(dyn_arr, self.output_shape)\n",
    "\n",
    "        # 拼接 5 通道: (C=5, D, H, W)\n",
    "        combined = np.stack([ct_data, pet_data,\n",
    "                             mr_dwi_data, mr_t1_data, mr_dynamic_data], axis=0)\n",
    "\n",
    "        combined_tensor = torch.tensor(combined, dtype=torch.float32)\n",
    "        label_tensor = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        if self.transform:\n",
    "            combined_tensor = self.transform(combined_tensor)\n",
    "\n",
    "        return combined_tensor, label_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import SimpleITK as sitk\n",
    "from skimage.transform import resize\n",
    "\n",
    "def load_dicom_series(folder_path):\n",
    "    \"\"\"\n",
    "    读取DICOM序列并返回 (D, H, W) 的 numpy array, 若失败则返回None\n",
    "    \"\"\"\n",
    "    if not folder_path or not os.path.isdir(folder_path):\n",
    "        return None\n",
    "\n",
    "    reader = sitk.ImageSeriesReader()\n",
    "    dicom_files = reader.GetGDCMSeriesFileNames(folder_path)\n",
    "    if len(dicom_files) == 0:\n",
    "        return None\n",
    "\n",
    "    reader.SetFileNames(dicom_files)\n",
    "    image = reader.Execute()  # SimpleITK image\n",
    "    array = sitk.GetArrayFromImage(image)  # (D, H, W)\n",
    "    return array\n",
    "\n",
    "def normalize_and_resize(image_np, output_shape=(64, 64, 64)):\n",
    "    \"\"\"\n",
    "    将 (D, H, W) 归一化到[0,1], 并 resize 到 output_shape.\n",
    "    若 image_np=None 或全0, 返回全0占位.\n",
    "    \"\"\"\n",
    "    if image_np is None or np.all(image_np == 0):\n",
    "        return np.zeros(output_shape, dtype=np.float32)\n",
    "\n",
    "    min_val, max_val = np.min(image_np), np.max(image_np)\n",
    "    if max_val - min_val < 1e-8:\n",
    "        image_np = np.zeros_like(image_np, dtype=np.float32)\n",
    "    else:\n",
    "        image_np = (image_np - min_val) / (max_val - min_val + 1e-8)\n",
    "\n",
    "    image_resized = resize(image_np, output_shape, mode='constant', anti_aliasing=True)\n",
    "    return image_resized.astype(np.float32)\n",
    "\n",
    "class MultiModal3DDataset(Dataset):\n",
    "    \"\"\"\n",
    "    5 通道: [CT, PET, MR_DWI, MR_T1, MR_DYNAMIC]\n",
    "    \"\"\"\n",
    "    def __init__(self, csv_path, transform=None, output_shape=(64,64,64)):\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.transform = transform\n",
    "        self.output_shape = output_shape\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        label = row[\"label\"]\n",
    "\n",
    "        # 1) CT\n",
    "        ct_path = row[\"ct_path\"] if isinstance(row[\"ct_path\"], str) and row[\"ct_path\"] else None\n",
    "        ct_data = load_dicom_series(ct_path)\n",
    "        ct_data = normalize_and_resize(ct_data, self.output_shape)\n",
    "\n",
    "        # 2) PET\n",
    "        pet_path = row[\"pet_path\"] if isinstance(row[\"pet_path\"], str) and row[\"pet_path\"] else None\n",
    "        pet_data = load_dicom_series(pet_path)\n",
    "        pet_data = normalize_and_resize(pet_data, self.output_shape)\n",
    "\n",
    "        # 3) MR_DWI\n",
    "        mr_dwi_str = row[\"mr_dwi\"] if isinstance(row[\"mr_dwi\"], str) else \"\"\n",
    "        mr_dwi_data = np.zeros(self.output_shape, dtype=np.float32)\n",
    "        if mr_dwi_str:\n",
    "            dwi_list = mr_dwi_str.split(\";\")\n",
    "            if len(dwi_list) > 0:  # 这里只示范取第一个文件夹\n",
    "                dwi_arr = load_dicom_series(dwi_list[0])\n",
    "                mr_dwi_data = normalize_and_resize(dwi_arr, self.output_shape)\n",
    "\n",
    "        # 4) MR_T1\n",
    "        mr_t1_str = row[\"mr_t1\"] if isinstance(row[\"mr_t1\"], str) else \"\"\n",
    "        mr_t1_data = np.zeros(self.output_shape, dtype=np.float32)\n",
    "        if mr_t1_str:\n",
    "            t1_list = mr_t1_str.split(\";\")\n",
    "            if len(t1_list) > 0:\n",
    "                t1_arr = load_dicom_series(t1_list[0])\n",
    "                mr_t1_data = normalize_and_resize(t1_arr, self.output_shape)\n",
    "\n",
    "        # 5) MR_dynamic\n",
    "        mr_dynamic_str = row[\"mr_dynamic\"] if isinstance(row[\"mr_dynamic\"], str) else \"\"\n",
    "        mr_dynamic_data = np.zeros(self.output_shape, dtype=np.float32)\n",
    "        if mr_dynamic_str:\n",
    "            dyn_list = mr_dynamic_str.split(\";\")\n",
    "            if len(dyn_list) > 0:\n",
    "                dyn_arr = load_dicom_series(dyn_list[0])\n",
    "                mr_dynamic_data = normalize_and_resize(dyn_arr, self.output_shape)\n",
    "\n",
    "        # 拼接 5 通道: (C=5, D, H, W)\n",
    "        combined = np.stack([ct_data, pet_data,\n",
    "                             mr_dwi_data, mr_t1_data, mr_dynamic_data], axis=0)\n",
    "\n",
    "        combined_tensor = torch.tensor(combined, dtype=torch.float32)\n",
    "        label_tensor = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        if self.transform:\n",
    "            combined_tensor = self.transform(combined_tensor)\n",
    "\n",
    "        return combined_tensor, label_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Simple3DCNN_5ch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 50\u001b[0m\n\u001b[0;32m     47\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m DataLoader(dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# 初始化网络, in_channels=5\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mSimple3DCNN_5ch\u001b[49m(in_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     51\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m     52\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Simple3DCNN_5ch' is not defined"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs320",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
